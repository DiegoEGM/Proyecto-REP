{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Proyecto Final \n",
        "##Reconocimiento Estadistico de patrones\n",
        "### Sebastian Sánchez Lara\n",
        "### Diego Emir Garcia Moreno\n"
      ],
      "metadata": {
        "id": "mUBbn0C6E-GM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preguntas\n",
        "\n",
        "1- ¿Existe alguna relacion entre la edad y las zonas donde se mueve la gente?¿Podemos ver clusters a partir esto?\n",
        "\n",
        "2- Dada la hora, edad, sexo, e inicio del viaje ¿Podemos predecir donde terminara el viaje?\n",
        "\n",
        "3- Hay clusters entre el mes del año y los tipos de viajes que hay?\n"
      ],
      "metadata": {
        "id": "y7ptqV2GtT3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ],
      "metadata": {
        "id": "WqGRk9GcGEYV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leemos los datos de la pagina web, para no gastarnos toda la RAM, usamos solo la mitas de los datos"
      ],
      "metadata": {
        "id": "GEjS-k6ibMvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Datos=[]\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1079/datos_abiertos_2014_12.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1097/datos_abiertos_2015_02.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1099/datos_abiertos_2015_04.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1101/datos_abiertos_2015_06.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1103/datos_abiertos_2015_08.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1105/datos_abiertos_2015_10.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1107/datos_abiertos_2015_12.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1021/datos_abiertos_2016_02.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1029/datos_abiertos_2016_04.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1080/datos_abiertos_2016_06.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1082/datos_abiertos_2016_08.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1108/datos_abiertos_2016_10.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1110/datos_abiertos_2016_12.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1111/datos_abiertos_2017_02.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1115/datos_abiertos_2017_04-1.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1119/datos_abiertos_2017_06.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1122/datos_abiertos_2017_08.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1124/datos_abiertos_2017_10.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1198/datos_abiertos_2017_12.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1201/datos_abiertos_2018_02.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1203/datos_abiertos_2018_04.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1205/datos_abiertos_2018_06.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1207/datos_abiertos_2018_08.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1209/datos_abiertos_2018_10.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1211/datos_abiertos_2018_12.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1217/datos_abiertos_2019_02.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1219/datos_abiertos_2019_04.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1221/datos_abiertos_2019_06.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1223/datos_abiertos_2019_08.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1225/datos_abiertos_2019_10.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1228/datos_abiertos_2019_12.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1231/datos_abiertos_2020_02.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1235/datos_abiertos_2020_04.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1237/datos_abiertos_2020_06.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1239/datos_abiertos_2020_08.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1241/datos_abiertos_2020_10.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1318/datos_abiertos_2020_12.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/1323/datos_abiertos_2021_02.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos.append(pd.read_csv('https://www.mibici.net/site/assets/files/2129/datos_abiertos_2021_04.csv',storage_options={\"User-Agent\": \"XY\"}))\n",
        "Datos=pd.concat(Datos)\n",
        "#print(Datos.head)\n",
        "#Limpiamos los datos\n",
        "Datos=Datos.dropna()\n",
        "print(Datos.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YLU3CfGGH_I",
        "outputId": "ef277ecf-d7ec-4e1c-93c5-d7264804b148"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of         Viaje_Id  Usuario_Id Genero  Año_de_nacimiento     Inicio_del_viaje  \\\n",
            "2           4628           3      F             1990.0  2014-12-01 09:47:20   \n",
            "3           4631         102      M             1982.0  2014-12-01 09:48:23   \n",
            "4           4632           3      F             1990.0  2014-12-01 09:48:46   \n",
            "5           4636           3      F             1990.0  2014-12-01 09:50:13   \n",
            "6           4637         102      M             1982.0  2014-12-01 09:49:05   \n",
            "...          ...         ...    ...                ...                  ...   \n",
            "240552  19092918      616437      M             1967.0  2021-04-30 23:58:14   \n",
            "240553  19092919       33303      F             1989.0  2021-04-30 23:58:43   \n",
            "240554  19092920      632442      M             1979.0  2021-04-30 23:59:09   \n",
            "240555  19092921      667653      M             1988.0  2021-04-30 23:59:24   \n",
            "240556  19092922     1006734      F             1987.0  2021-04-30 23:59:32   \n",
            "\n",
            "              Fin_del_viaje  Origen_Id  Destino_Id  \n",
            "2       2014-12-01 09:47:47         79          79  \n",
            "3       2014-12-01 09:48:37         79          79  \n",
            "4       2014-12-01 09:48:57         79          79  \n",
            "5       2014-12-01 09:50:18         79          79  \n",
            "6       2014-12-01 09:49:17         79          79  \n",
            "...                     ...        ...         ...  \n",
            "240552  2021-05-01 00:09:05        289         292  \n",
            "240553  2021-05-01 00:14:54         63          12  \n",
            "240554  2021-05-01 00:27:20         51         271  \n",
            "240555  2021-05-01 00:06:02        130         306  \n",
            "240556  2021-05-01 00:13:01         61          75  \n",
            "\n",
            "[7751164 rows x 8 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nomenclatura=pd.read_csv('https://www.mibici.net/site/assets/files/1118/nomenclatura_2023_05.csv',storage_options={\"User-Agent\": \"XY\"},encoding=\"latin1\")\n",
        "EstacionAZona={nomenclatura.loc[i][0]:nomenclatura.loc[i][3]for i in range(len(nomenclatura))}\n",
        "to_num = {'POLÍGONO CENTRAL':0, 'TLQ-CORREDORATLAS':1, 'ZAPOPAN CENTRO':2}\n",
        "dataIndex=[]\n",
        "cont=[0,0,0]\n",
        "for i in range(len(Datos)):\n",
        "  #print(Datos.iloc[i,6])\n",
        "  if Datos.iloc[i,6]==124:\n",
        "    continue\n",
        "  if cont[to_num[EstacionAZona[Datos.iloc[i,6]]]]<1000:\n",
        "    cont[to_num[EstacionAZona[Datos.iloc[i,6]]]]+=1\n",
        "    dataIndex.append(i)\n",
        "DatosProblema2=Datos.iloc[dataIndex].head"
      ],
      "metadata": {
        "id": "kPPiHvooYkOO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segunda Pregunta \n",
        "Dada la hora, edad, sexo, e inicio del viaje ¿Podemos predecir donde terminara el viaje?\n"
      ],
      "metadata": {
        "id": "szzGcpDOpzhw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación intentamos responder la segunda pregunta. Para esto utilizamos **redes neuronales**."
      ],
      "metadata": {
        "id": "I5wnfLy4nuoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Funciones para parsear fechas\n",
        "def parsea(s):\n",
        "  #Dia/Mes/Anio HH:MM:SS [a. m./ p. m] regresa HH:MM:SS convertida a segundos\n",
        "  p = s.find(' ') + 1\n",
        "  return 60 * 60 * int(s[p : p + 2]) + 60 * int(s[p + 3 : p + 5]) + int(s[p + 6 : p + 8])\n",
        "\n",
        "def conv(n): \n",
        "  if n < 10:\n",
        "    return '0' + str(n)\n",
        "  return str(n)\n",
        "\n",
        "def a_hora(n): #Dados segundos, convierte a HH:MM:SS\n",
        "  h = n // (60 * 60)\n",
        "  n -= h * 60 * 60\n",
        "  m = n // 60\n",
        "  n -= m * 60\n",
        "  s = int(n)\n",
        "  ret = conv(h) + ':' + conv(m) + ':' + conv(s)\n",
        "  return ret   "
      ],
      "metadata": {
        "id": "Km_cwgs7cqSF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardamos en un arreglo X los datos que nos interesan: hora de inicio, lugar de inicio, fecha de nacimiento, y genero. En Y se guarda su correspondiente lugar de llegada."
      ],
      "metadata": {
        "id": "FycifLLEn-Uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(Datos)\n",
        "X = np.zeros((n, 4), dtype = 'd')\n",
        "for i in range(n): #Tiempo de inicio\n",
        "  X[i][0] = parsea(Datos.iloc[i, 4])\n",
        "X[:, 1] = Datos.iloc[:, 6].values #Origen_id (Inicio)\n",
        "X[:, 2] = Datos.iloc[:, 3].values #Nacimiento\n",
        "for i in range(n): #Genero\n",
        "  if Datos.iloc[i, 2] == 'M':\n",
        "    X[i][3] = 0\n",
        "  else:\n",
        "    X[i][3] = 1\n",
        "X = (X - np.mean(X)) / np.std(X)\n",
        "Y = Datos.iloc[:, 7].values #Destino_id (Fin)"
      ],
      "metadata": {
        "id": "S-lQPuhdcXBz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos una red neuronal para clasificar de acuerdo al ID del lugar de llegada."
      ],
      "metadata": {
        "id": "XifDfNTQoLJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier #for classification problems\n",
        "from sklearn.neural_network import MLPRegressor  #for regression problems\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "oIWSy4ETfqgG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos los datos en un conjunto de prueba y un conjunto de entrenamiento"
      ],
      "metadata": {
        "id": "egTMwSXxoTk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 30)"
      ],
      "metadata": {
        "id": "NyhtvZMHeUWm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def error(pred, real_val):\n",
        "  e = 0\n",
        "  for i in range(len(pred)):\n",
        "    e += pred[i] != real_val[i]\n",
        "  return e"
      ],
      "metadata": {
        "id": "9L0s_PhqiPvv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error de entrenamiento"
      ],
      "metadata": {
        "id": "C8NAGJuyoj9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_neuronas_train = range(1, 5)\n",
        "err_train = []\n",
        "\n",
        "for n in num_neuronas_train:\n",
        "  clf = MLPClassifier( hidden_layer_sizes= (n),solver=\"lbfgs\",max_iter=200,alpha=0)\n",
        "  clf.fit(X_train,Y_train) \n",
        "  prd = clf.predict(X_train)\n",
        "  err_n = error(prd, Y_train)\n",
        "  print(n, \"neuronas\", err_n, \" incorrectas\", \" porcentaje de error es \", err_n * 100 / len(X_train))\n",
        "  err_train.append(err_n)\n"
      ],
      "metadata": {
        "id": "ik4rNhykiSi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error de prueba"
      ],
      "metadata": {
        "id": "h7ZHasieom3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier( hidden_layer_sizes= (20,20),solver=\"sgd\",max_iter=2000,alpha=0)\n",
        "clf.fit(X_train,Y_train) \n",
        "prd = clf.predict(X_test)\n",
        "err_n = error(prd, Y_test)\n",
        "print((10,10), \"neuronas\", err_n, \" incorrectas\", \" porcentaje de error es \", err_n * 100 / len(X_test))\n"
      ],
      "metadata": {
        "id": "bSa9Kk-Ei1l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con las pruebas realizadas se obtuvo un porcentaje de acierto muy bajo. Esto es, no existe una relación entre las características consideradas y el lugar de llegada, o bien las redes neuronales no permiten responder esta pregunta.\n",
        "\n",
        "Ahora intentaremos predecir la misma caracteristica usando el **clasificador Bayesiano optimo**."
      ],
      "metadata": {
        "id": "rLIuDMtNoa2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import CategoricalNB\n",
        "clf = GaussianNB()\n",
        "#clf = CategoricalNB(force_alpha=True)\n",
        "clf.fit(X_train, Y_train)\n",
        "CategoricalNB(force_alpha=True)\n",
        "print(\"porcentaje de error de entrenamiento\", 100 - 100 * clf.score(X_train, Y_train), '%')\n",
        "print(\"porcentaje de error de prueba\", 100 - 100 * clf.score(X_test, Y_test), '%')\n"
      ],
      "metadata": {
        "id": "zNNJjaQeq2xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pesar de que el error sigue siendo muy alto, notamos que el es menor que el de la red neuronal.\n",
        "\n",
        "Finalmente intentamos clasificar usando k-NN."
      ],
      "metadata": {
        "id": "JbismFbcsMHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "knn.fit(X_train, Y_train)\n",
        "print(\"error de \", 100 - knn.score(X_test, Y_test) * 100, '%')"
      ],
      "metadata": {
        "id": "hVvGTGHhHN1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que con los metodos anteriores, no se obtuvo una buena clasificacion.\n",
        "Intentaremos ahora clasificar de acuerdo a la zona de la estacion, lo cual es menos restrictivo. "
      ],
      "metadata": {
        "id": "eJlO02eIP9c1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos los arreglos de las nuevas etiquetas"
      ],
      "metadata": {
        "id": "JF_b_p2ZR07n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test2 = [EstacionAZona[x] for x in Y_test]\n",
        "Y_train2 = [EstacionAZona[x] for x in Y_train]"
      ],
      "metadata": {
        "id": "c6LW5UceQSVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier( hidden_layer_sizes= (20,20),solver=\"sgd\",max_iter=2000,alpha=0)\n",
        "clf.fit(X_train,Y_train2) \n",
        "pred = clf.predict(X_test)\n",
        "err_n = error(pred, Y_test2)\n",
        "\n",
        "print((10,10), \"neuronas\", err_n, \" incorrectas\", \" porcentaje de error es \", err_n * 100 / len(X_test))\n",
        "\n",
        "tot = np.zeros(3)\n",
        "err = np.zeros(3)\n",
        "to_num = {'POLÍGONO CENTRAL':0, 'TLQ-CORREDORATLAS':1, 'ZAPOPAN CENTRO':2}\n",
        "\n",
        "for i in range(len(Y_test2)):\n",
        "  tot[to_num[Y_test2[i]]] += 1\n",
        "  if Y_test2[i] != pred[i]:\n",
        "    err[to_num[Y_test2[i]]] += 1\n",
        "\n",
        "for i in range(3):\n",
        "  print(\"zona \", i, \" falsos \", err[i], \" de \", tot[i], \" error de \", err[i] * 100 / tot[i], '%')"
      ],
      "metadata": {
        "id": "_m6Ht8xUXtfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos clasificador\n",
        " Bayesiano"
      ],
      "metadata": {
        "id": "htG2sWaeR4-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import CategoricalNB\n",
        "clf = GaussianNB()\n",
        "#clf = CategoricalNB(force_alpha=True)\n",
        "clf.fit(X_train, Y_train2)\n",
        "pred = clf.predict(X_test)\n",
        "CategoricalNB(force_alpha=True)\n",
        "print(\"porcentaje de error de entrenamiento\", 100 - 100 * clf.score(X_train, Y_train2), '%')\n",
        "print(\"porcentaje de error de prueba\", 100 - 100 * clf.score(X_test, Y_test2), '%')\n",
        "\n",
        "tot = np.zeros(3)\n",
        "err = np.zeros(3)\n",
        "to_num = {'POLÍGONO CENTRAL':0, 'TLQ-CORREDORATLAS':1, 'ZAPOPAN CENTRO':2}\n",
        "\n",
        "for i in range(len(Y_test2)):\n",
        "  tot[to_num[Y_test2[i]]] += 1\n",
        "  if Y_test2[i] != pred[i]:\n",
        "    err[to_num[Y_test2[i]]] += 1\n",
        "\n",
        "for i in range(3):\n",
        "  print(\"zona \", i, \" falsos \", err[i], \" de \", tot[i], \" error de \", err[i] * 100 / tot[i], '%')"
      ],
      "metadata": {
        "id": "0DGHNb0qRf5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos kNN"
      ],
      "metadata": {
        "id": "yQAp_RvkR7pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "knn.fit(X_train, Y_train2)\n",
        "pred = knn.predict(X_test)\n",
        "print(\"error de \", 100 - knn.score(X_test, Y_test2) * 100, '%')\n",
        "\n",
        "tot = np.zeros(3)\n",
        "err = np.zeros(3)\n",
        "to_num = {'POLÍGONO CENTRAL':0, 'TLQ-CORREDORATLAS':1, 'ZAPOPAN CENTRO':2}\n",
        "\n",
        "for i in range(len(Y_test2)):\n",
        "  tot[to_num[Y_test2[i]]] += 1\n",
        "  if Y_test2[i] != pred[i]:\n",
        "    err[to_num[Y_test2[i]]] += 1\n",
        "\n",
        "for i in range(3):\n",
        "  print(\"zona \", i, \" falsos \", err[i], \" de \", tot[i], \" error de \", err[i] * 100 / tot[i], '%')"
      ],
      "metadata": {
        "id": "22Zz-Zb8Qrbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nomenclatura=pd.read_csv('https://www.mibici.net/site/assets/files/1118/nomenclatura_2023_05.csv',storage_options={\"User-Agent\": \"XY\"},encoding=\"latin1\")\n",
        "EstacionAZona={nomenclatura.loc[i][0]:nomenclatura.loc[i][3]for i in range(len(nomenclatura))}\n",
        "to_num = {'POLÍGONO CENTRAL':0, 'TLQ-CORREDORATLAS':1, 'ZAPOPAN CENTRO':2}\n",
        "dataIndex=[]\n",
        "cont=[0,0,0]\n",
        "for i in range(len(Datos)):\n",
        "  #print(Datos.iloc[i,6])\n",
        "  if Datos.iloc[i,6]==124:\n",
        "    continue\n",
        "  if cont[to_num[EstacionAZona[Datos.iloc[i,6]]]]<1000:\n",
        "    cont[to_num[EstacionAZona[Datos.iloc[i,6]]]]+=1\n",
        "    dataIndex.append(i)\n",
        "DatosEquilibradosPorZona=Datos.iloc[dataIndex]"
      ],
      "metadata": {
        "id": "9amQ9DT8gOME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(DatosEquilibradosPorZona)\n",
        "X = np.zeros((n, 4), dtype = 'd')\n",
        "for i in range(n): #Tiempo de inicio\n",
        "  X[i][0] = parsea(DatosEquilibradosPorZona.iloc[i, 4])\n",
        "X[:, 1] = DatosEquilibradosPorZona.iloc[:, 6].values #Origen_id (Inicio)\n",
        "X[:, 2] = DatosEquilibradosPorZona.iloc[:, 3].values #Nacimiento\n",
        "for i in range(n): #Genero\n",
        "  if DatosEquilibradosPorZona.iloc[i, 2] == 'M':\n",
        "    X[i][3] = 0\n",
        "  else:\n",
        "    X[i][3] = 1\n",
        "X = (X - np.mean(X)) / np.std(X)\n",
        "Y = DatosEquilibradosPorZona.iloc[:, 7].values #Destino_id (Fin)"
      ],
      "metadata": {
        "id": "yzhR3Cqhg2Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 30)\n",
        "Y_test2 = [EstacionAZona[x] for x in Y_test]\n",
        "Y_train2 = [EstacionAZona[x] for x in Y_train]"
      ],
      "metadata": {
        "id": "asI4lsYWgmZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier( hidden_layer_sizes= (20,20),solver=\"sgd\",max_iter=2000,alpha=0)\n",
        "clf.fit(X_train,Y_train2) \n",
        "pred = clf.predict(X_test)\n",
        "err_n = error(pred, Y_test2)\n",
        "\n",
        "print((10,10), \"neuronas\", err_n, \" incorrectas\", \" porcentaje de error es \", err_n * 100 / len(X_test))\n",
        "\n",
        "tot = np.zeros(3)\n",
        "err = np.zeros(3)\n",
        "to_num = {'POLÍGONO CENTRAL':0, 'TLQ-CORREDORATLAS':1, 'ZAPOPAN CENTRO':2}\n",
        "\n",
        "for i in range(len(Y_test2)):\n",
        "  tot[to_num[Y_test2[i]]] += 1\n",
        "  if Y_test2[i] != pred[i]:\n",
        "    err[to_num[Y_test2[i]]] += 1\n",
        "\n",
        "for i in range(3):\n",
        "  print(\"zona \", i, \" falsos \", err[i], \" de \", tot[i], \" error de \", err[i] * 100 / tot[i], '%')"
      ],
      "metadata": {
        "id": "xfGzTh-2iV3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, Y_train2)\n",
        "pred = clf.predict(X_test)\n",
        "GaussianNB()\n",
        "print(\"porcentaje de error de entrenamiento\", 100 - 100 * clf.score(X_train, Y_train2), '%')\n",
        "print(\"porcentaje de error de prueba\", 100 - 100 * clf.score(X_test, Y_test2), '%')\n",
        "\n",
        "tot = np.zeros(3)\n",
        "err = np.zeros(3)\n",
        "to_num = {'POLÍGONO CENTRAL':0, 'TLQ-CORREDORATLAS':1, 'ZAPOPAN CENTRO':2}\n",
        "\n",
        "for i in range(len(Y_test2)):\n",
        "  tot[to_num[Y_test2[i]]] += 1\n",
        "  if Y_test2[i] != pred[i]:\n",
        "    err[to_num[Y_test2[i]]] += 1\n",
        "\n",
        "for i in range(3):\n",
        "  print(\"zona \", i, \" falsos \", err[i], \" de \", tot[i], \" error de \", err[i] * 100 / tot[i], '%')"
      ],
      "metadata": {
        "id": "7scQTnd2iFfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "knn.fit(X_train, Y_train2)\n",
        "pred = knn.predict(X_test)\n",
        "print(\"error de \", 100 - knn.score(X_test, Y_test2) * 100, '%')\n",
        "\n",
        "tot = np.zeros(3)\n",
        "err = np.zeros(3)\n",
        "to_num = {'POLÍGONO CENTRAL':0, 'TLQ-CORREDORATLAS':1, 'ZAPOPAN CENTRO':2}\n",
        "\n",
        "for i in range(len(Y_test2)):\n",
        "  tot[to_num[Y_test2[i]]] += 1\n",
        "  if Y_test2[i] != pred[i]:\n",
        "    err[to_num[Y_test2[i]]] += 1\n",
        "\n",
        "for i in range(3):\n",
        "  print(\"zona \", i, \" falsos \", err[i], \" de \", tot[i], \" error de \", err[i] * 100 / tot[i], '%')"
      ],
      "metadata": {
        "id": "rP_p35N4geMV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}